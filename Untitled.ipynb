{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from mydataset import MyDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "nways = 5\n",
    "44\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([8, 3, 5, 105, 105]) torch.Size([8, 3, 5, 6])\n",
      "torch.Size([8, 15, 6]) torch.Size([8, 15, 11025])\n",
      "torch.Size([8, 15, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, k, n, ntrain, is_train):\n",
    "        super().__init__()\n",
    "        self.n_examples_per_class = 20\n",
    "        self.dataset = torchvision.datasets.Omniglot(\n",
    "            root=\"./data\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "        )\n",
    "        self.nclasses = len(self.dataset)//self.n_examples_per_class\n",
    "        self.ntrain = ntrain\n",
    "        self.is_train = is_train\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        assert ntrain <= self.nclasses, \"ntrain examples should be less than or equal to total number of examples(20)\"\n",
    "    def __len__(self):\n",
    "        return 1234\n",
    "    def get_one_random(self, iclass):\n",
    "        i2 = 0\n",
    "        if self.is_train:\n",
    "            i2 = random.randint(0, self.ntrain-1)\n",
    "        else:\n",
    "            i2 = random.randint(self.ntrain, self.n_examples_per_class-1)\n",
    "        a, _ = self.dataset[iclass*self.n_examples_per_class + i2]\n",
    "        return a.unsqueeze(0).unsqueeze(0) #, torch.tensor([[b]]).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        llt1=[]; rng=0;\n",
    "        if self.is_train:\n",
    "            rlist = random.sample(range(0, self.ntrain-1), self.n)\n",
    "        else:\n",
    "            rlist = random.sample(range(self.ntrain, self.nclasses), self.n)\n",
    "        for nk in range(self.k):\n",
    "            lt1=[]; lt2=[]\n",
    "            for iclass in rlist:\n",
    "                t1 = self.get_one_random(iclass)\n",
    "                lt1.append(t1)\n",
    "            llt1.append(torch.cat(lt1, dim=1))\n",
    "        t1 = torch.cat(llt1, dim=0).squeeze(-3)\n",
    "        \n",
    "        l = list(range(0, self.n))\n",
    "        t2 = torch.tensor([l])\n",
    "        t2 = t2.repeat(self.k, 1, 1)\n",
    "        t2 = F.one_hot(t2, num_classes=nways+1).squeeze(-3)\n",
    "            \n",
    "            \n",
    "        return t1, t2\n",
    "        \n",
    "dataset = MyDataset(k=3, n=nways, ntrain=100, is_train=True)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, num_workers=3)\n",
    "      \n",
    "# image, label = dataset[50]\n",
    "# print(label)  # int\n",
    "# plt.imshow(image.numpy()[0])\n",
    "for t in loader:\n",
    "    print(t[0].shape, t[1].shape)\n",
    "    ns = t[0][0, 0, 0, :, :].numpy()\n",
    "    print(model(t[0], t[1]).shape)\n",
    "    plt.imshow(ns)\n",
    "    break# next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.pixs = 105**2\n",
    "        self.lin = nn.Linear(128, nways)\n",
    "        self.lstm = nn.LSTM(self.pixs+nways+1, 128, num_layers=2, batch_first=True)\n",
    "    def forward(self, x, idx):\n",
    "        x = x.view(x.shape[0], -1, self.pixs)\n",
    "        idx = idx.view(idx.shape[0], -1, nways+1).float()\n",
    "#         print(idx.shape, x.shape)\n",
    "        \n",
    "        h = torch.cat((x, idx), dim=-1)\n",
    "        h, _ = self.lstm(h)\n",
    "        h = self.lin(h)\n",
    "        h = torch.softmax(h, dim=-1)\n",
    "        return h\n",
    "        \n",
    "        \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ename = 'tst1'\n",
    "os.system('mkdir tb/'+ename)\n",
    "writer = SummaryWriter('tb/'+ename)\n",
    "\n",
    "\n",
    "\n",
    "eps=10\n",
    "for ep in range(eps):\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        xexamples, xtoguess = x[:, :-1, :, :], x[:, -1, :, :]\n",
    "        yexamples, ytoguess = y[:, :-1, :, :], y[:, -1, :, :]\n",
    "        \n",
    "        \n",
    "        break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
