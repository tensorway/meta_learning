{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit41770f51cb494085b126429b02db281f",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mydataset import MyDataset, acc\n",
    "import random\n",
    "\n",
    "import copy\n",
    "\n",
    "nways = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\nFiles already downloaded and verified\n"
    }
   ],
   "source": [
    "bsize = 8\n",
    "ksize = 5\n",
    "dataset = MyDataset(k=ksize+1, n=nways, ntrain=800, is_train=True)\n",
    "dataset_test = MyDataset(k=ksize, n=nways, ntrain=800, is_train=False)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=bsize, num_workers=3)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=bsize, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.pixs = 27**2\n",
    "        self.lin1 = nn.Linear(512+self.pixs, 64)\n",
    "        self.lin2 = nn.Linear(64, nways)\n",
    "        self.lstm = nn.LSTM(self.pixs+nways, 512, num_layers=2, batch_first=True)\n",
    "\n",
    "    def forward(self, x, idx, x2):\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2], self.pixs).view(x.shape[0], -1, self.pixs)\n",
    "        idx = idx.view(idx.shape[0], -1, nways).float()\n",
    "        x2 = x2.view(x2.shape[0], nways, self.pixs)\n",
    "        h = torch.cat((x, idx), dim=-1)\n",
    "        _, (h, _) = self.lstm(h)\n",
    "        h = h.view(2, 1, x.shape[0], -1)[1].squeeze(0).unsqueeze(1).repeat(1, nways, 1)\n",
    "        h2 = torch.cat((x2, h), dim=-1)\n",
    "        h2 = self.lin1(h2)\n",
    "        h2 = F.relu(h2)\n",
    "        h2 = self.lin2(h2)\n",
    "        h2 = torch.softmax(h2, dim=-1)\n",
    "        return h2\n",
    "        \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, ):\n",
    "        l = [nn.Conv2d(1, 32), nn.Conv2d(32, 64), nn.Conv2d(64, 64)]\n",
    "        self.convs = nn.ModuleList(l)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.lin1 = nn.Linear(512, 64)\n",
    "        self.lstm = nn.LSTM(64, 64, num_layers=1, batch_first=True)\n",
    "\n",
    "    def forward(self, x_train, y_train, x_test, y_test):\n",
    "        h = h0 = x_train.view(-1, 1, x.shape[-2], x.shape[-1])\n",
    "        h = h0 = x_test.view(-1, 1, x.shape[-2], x.shape[-1])\n",
    "        for conv in self.convs:\n",
    "            h = conv(h)\n",
    "            h = self.pool(h)\n",
    "            h = F.relu(h)\n",
    "        h = h.view(x_train.shape[0], -1, )\n",
    "        h = F.relu(self.lin1(h))\n",
    "        _, (h, _) = self.lstm(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ename = 'tst_hdim512_b512_long'\n",
    "os.system('mkdir tb/'+ename)\n",
    "writer = SummaryWriter('tb/'+ename)\n",
    "\n",
    "ii = 0\n",
    "eps=1000\n",
    "for ep in range(eps):\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        xexamples, xtoguess = x[:, :-1], x[:, -1]\n",
    "        yexamples, ytoguess = y[:, :-1], y[:, -1]\n",
    "        preds = model(xexamples, yexamples, xtoguess)\n",
    "        loss = -(ytoguess*torch.log(preds+1e-8)).mean()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        accu = acc(ytoguess, preds)\n",
    "        writer.add_scalar(\"loss/accuracy\", accu, ii:=ii+1)\n",
    "        writer.add_scalar(\"loss/loss\", loss.item(), ii)\n",
    "        if step%4==0:\n",
    "            print(ep, step, loss.item(), accu)"
   ]
  }
 ]
}